{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C:\\\\Program Files\\\\WindowsApps\\\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\\\python311.zip', 'C:\\\\Program Files\\\\WindowsApps\\\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\\\DLLs', 'C:\\\\Program Files\\\\WindowsApps\\\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\\\Lib', 'C:\\\\Program Files\\\\WindowsApps\\\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0', 'c:\\\\Users\\\\juans\\\\OneDrive\\\\Documentos\\\\iaProyect\\\\Cognitive\\\\.venv', '', 'c:\\\\Users\\\\juans\\\\OneDrive\\\\Documentos\\\\iaProyect\\\\Cognitive\\\\.venv\\\\Lib\\\\site-packages', 'c:\\\\Users\\\\juans\\\\OneDrive\\\\Documentos\\\\iaProyect\\\\Cognitive\\\\.venv\\\\Lib\\\\site-packages\\\\win32', 'c:\\\\Users\\\\juans\\\\OneDrive\\\\Documentos\\\\iaProyect\\\\Cognitive\\\\.venv\\\\Lib\\\\site-packages\\\\win32\\\\lib', 'c:\\\\Users\\\\juans\\\\OneDrive\\\\Documentos\\\\iaProyect\\\\Cognitive\\\\.venv\\\\Lib\\\\site-packages\\\\Pythonwin', 'C:/Users/juans/OneDrive/Documentos/iaProyect/Cognitive', 'C:/Users/juans/OneDrive/Documentos/iaProyect/Cognitive', 'C:/Users/juans/OneDrive/Documentos/iaProyect/Cognitive']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('C:/Users/juans/OneDrive/Documentos/iaProyect/Cognitive')\n",
    "print(sys.path)  # Esto mostrará todas las rutas en sys.path\n",
    "\n",
    "from model.preprocessing.data_cleaning import DataCleaner\n",
    "from model.utils.data_analysis import DataAnalyzer\n",
    "#from model.preprocessing.data_extraction import DataExtractor\n",
    "from model.preprocessing.feature_extraction import FeatureSelector,FeatureVisualizer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "import unidecode\n",
    "import csv\n",
    "\n",
    "class DataExtractor:\n",
    "    def __init__(self, base_path=\"../../data/\", columns_to_drop=None):\n",
    "        self.base_path = base_path\n",
    "        self.columns_to_drop = columns_to_drop if columns_to_drop is not None else []\n",
    "        self.removed_features = []  # Almacena los nombres de las características eliminadas\n",
    "        self.removed_rows = []  # Almacena las filas problemáticas\n",
    "\n",
    "    def preprocess_csv(self, input_path, output_path, encoding='latin1'):\n",
    "        with open(input_path, 'r', encoding=encoding) as infile, \\\n",
    "            open(output_path, 'w', encoding=encoding) as outfile:\n",
    "            current_line = []\n",
    "            for line in infile:\n",
    "                # Comprobar si la línea comienza con un número de cinco o más dígitos\n",
    "                if line.strip() and line[:5].isdigit() and current_line:\n",
    "                    # Escribir la línea acumulada en el archivo de salida\n",
    "                    outfile.write(''.join(current_line).replace('\\n', ' ') + '\\n')\n",
    "                    current_line = [line]  # Comenzar una nueva línea acumulada\n",
    "                else:\n",
    "                    # Continuar acumulando segmentos de la línea actual\n",
    "                    current_line.append(line)\n",
    "            # Escribir la última línea acumulada\n",
    "            if current_line:\n",
    "                outfile.write(''.join(current_line).replace('\\n', ' ') + '\\n')\n",
    "\n",
    "    def load_data(self, nameFolderRaw, file_name, processed_file_name='processed.csv', encoding='latin1', delimiter=';'):\n",
    "        original_path = self.base_path + nameFolderRaw + file_name\n",
    "        processed_path = self.base_path + nameFolderRaw + processed_file_name\n",
    "        # Preprocesar el archivo para limpiar los saltos de línea incorrectos\n",
    "        self.preprocess_csv(original_path, processed_path, encoding=encoding)\n",
    "        \n",
    "        try:\n",
    "            data = pd.read_csv(processed_path, \n",
    "                               encoding=encoding, \n",
    "                               delimiter=delimiter, \n",
    "                               header=0,\n",
    "                               quoting=csv.QUOTE_NONE,\n",
    "                               on_bad_lines='skip')\n",
    "        except pd.errors.ParserError as e:\n",
    "            print(f\"Error al leer el archivo: {e}\")\n",
    "            return None\n",
    "\n",
    "        object_columns = data.select_dtypes(include=[object]).columns\n",
    "        for col in object_columns:\n",
    "            data[col] = data[col].apply(lambda x: unidecode.unidecode(x) if isinstance(x, str) else x)\n",
    "\n",
    "        if self.columns_to_drop:\n",
    "            data.drop(columns=self.columns_to_drop, inplace=True, errors='ignore')\n",
    "\n",
    "        return data\n",
    "\n",
    "\n",
    "    def get_removed_features(self):\n",
    "        return self.removed_features\n",
    "\n",
    "    def get_removed_rows(self):\n",
    "        return self.removed_rows\n",
    "\n",
    "    @staticmethod\n",
    "    def save_data_pickle(data, namefile, base_path, filter_condition=None):\n",
    "        if filter_condition:\n",
    "            data = data.query(filter_condition)\n",
    "        with open(base_path + \"processed/\" + namefile, 'wb') as f:\n",
    "            pickle.dump(data, f)\n",
    "\n",
    "    @staticmethod\n",
    "    def extract_test_validation_training_data(data, target_column='Deterioro Cognitivo', training_ratio=0.7, test_ratio=0.2, validation_ratio=0.1):\n",
    "        if target_column not in data.columns:\n",
    "            raise ValueError(f\"La columna objetivo '{target_column}' no se encuentra en los datos\")\n",
    "\n",
    "        training_data, temp_data = train_test_split(data, test_size=1-training_ratio, random_state=42)\n",
    "        validation_data, test_data = train_test_split(temp_data, test_size=(validation_ratio / (test_ratio + validation_ratio)), random_state=42)\n",
    "\n",
    "        return {\n",
    "            'train': (training_data.drop(columns=[target_column]), training_data[target_column]),\n",
    "            'validation': (validation_data.drop(columns=[target_column]), validation_data[target_column]),\n",
    "            'test': (test_data.drop(columns=[target_column]), test_data[target_column])\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\juans\\AppData\\Local\\Temp\\ipykernel_39896\\1936011678.py:38: DtypeWarning: Columns (44,67,95,102,174,175,211,213,231,232,234,257,258,260,265,267) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv(processed_path,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Identificación  Lugar Nacimiento  Municipio Atención  Edad  Género  \\\n",
      "0       10035213                 0                 1.0  63.0     0.0   \n",
      "1       10055205                 2                 3.0  79.0     0.0   \n",
      "2       10056901                 3                 3.0  73.0     0.0   \n",
      "3       10061985                 6                 3.0  71.0     0.0   \n",
      "4       10065630                 6                 3.0  69.0     0.0   \n",
      "\n",
      "   Grupo Sanguíneo  Lateralidad  Autopercepción Salud  Estado Civil  \\\n",
      "0              7.0          1.0                     1           1.0   \n",
      "1              6.0          1.0                     1           0.0   \n",
      "2              7.0          1.0                     1           1.0   \n",
      "3              0.0          1.0                     1           2.0   \n",
      "4              0.0          1.0                     0           1.0   \n",
      "\n",
      "  Vive con pareja  ...  Cdr Orientacion Cdr Juicio  Cdr Vida Social  \\\n",
      "0               1  ...              0.0        0.5                0   \n",
      "1               0  ...              2.0        0.5              0.5   \n",
      "2               1  ...              0.0        0.0                0   \n",
      "3               0  ...              0.5        1.0                0   \n",
      "4               1  ...              0.5        0.0                0   \n",
      "\n",
      "   Cdr Hogar Y Aficiones  Cdr Cuidado Personal  Total Cdr  \\\n",
      "0                    0.0                   0.0        0.0   \n",
      "1                    0.5                   0.0        0.5   \n",
      "2                    0.0                   0.0        0.0   \n",
      "3                    0.0                   0.0        0.5   \n",
      "4                    1.0                   0.0        0.0   \n",
      "\n",
      "                                     Observacion Cdr  Deterioro Cognitivo  \\\n",
      "0  \"Ausencia de quejas de memoria.  Allegados le ...                  0.0   \n",
      "1  Es ocasional que olvide donde ha dejado objeto...                  1.0   \n",
      "2  Parece subvalorar sintomatologia. dice tener u...                  0.0   \n",
      "3  En ocasiones olvida que  ha cambiado el puesto...                  0.0   \n",
      "4                                                NaN                  0.0   \n",
      "\n",
      "                            Observacion Especialista  Médico Atención   \n",
      "0                                                NaN               0.0  \n",
      "1        Analfabeta.  No computan MoCA ni Minimental               1.0  \n",
      "2                                                NaN               1.0  \n",
      "3  Sujeto analfabeta. no computan moca ni minimen...               1.0  \n",
      "4                                                NaN               1.0  \n",
      "\n",
      "[5 rows x 268 columns]\n"
     ]
    }
   ],
   "source": [
    "# Ejemplo de uso\n",
    "datahandler = DataExtractor()\n",
    "data = datahandler.load_data(\"raw/\", \"BD sin RM(Base de datos) (2).csv\")\n",
    "if data is not None:\n",
    "    print(data.head())\n",
    "else:\n",
    "    print(\"No se pudo cargar los datos.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2666 entries, 0 to 2665\n",
      "Columns: 268 entries, Identificación to Médico Atención \n",
      "dtypes: float64(198), int64(4), object(66)\n",
      "memory usage: 5.5+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(data.info(max_cols=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2997 entries, 0 to 2996\n",
      "Data columns (total 1 columns):\n",
      " #   Column                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            Non-Null Count  Dtype \n",
      "---  ------                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            --------------  ----- \n",
      " 0   Identificación;Lugar Nacimiento;Municipio Atención;Edad;Género;Grupo Sanguíneo;Lateralidad;Autopercepción Salud;Estado Civil;Vive con pareja;Número Hijos;Tipo Vivienda;Número Personas Viven Casa;Vive solo;Estrato;Escolaridad;Ocupación;Salario;Antecedentes Alcohol;Antecedentes Tabaco;Antecedentes Sustancias Psicoactivas;Antecedentes Hta;MHTA-1;MHTA-2;MHTA-3;Tiazida;Calcioantagonista;Betabloqueador;I-ECA;ARA-II;D-ASA;AH-K;B-ALFA;B-ADRE;ASA;Antecedentes Sindrome Coronario;Tipo SC;MSC-1;MSC-1;STENT;NITRATOS;CLOPIDO;Antecedentes Arritmias Cardiacas;MARR-1;MARR-2;AMIODARONA;ANTICOAG;DIGITAL;Antecedentes Acv;Tipo ACV;Antecedentes Dislipidemia;Tipo dislipidemia;Tipo dislipidemia;M-DISL;ESTATINA;FIBRATOS;Antecedentes EPOC;MEPOC;B2;ANTICOL;GLUC-I;TEOFI;ANTILEUCO;OXIG;Antecedentes ERC;MERC-1;MERC-2;MERC-3;CALCIO;A. FOLIC;COM. B;Antecedentes Cancer;Tipo cancer;Antecedentes Diabetes;Tipo DM;Insulinoterapia;MDM-1;MDM-2;i-DDP4;Biguanida;A-GLP1;Sulfonilureas;I-rápida;I-NPH;I-prolongada;Antecedentes Alteraciones Tiroideas;Tipo Alt. Tiroidea;Hipotiroidismo;MTIR;M. Tiroides;Antecedentes Problemas Auditivos;Tipo problema auditivo;Hipoacusia;Antecedentes visuales;Tipo problema visuales;Disminución agudeza visual;Antecedentes Demencias;Antecedentes Convulsiones;Desc. Convulsiones;Epilepsia;Antecedentes Tec;Tipo TEC;Antecedentes Enfermedades Psiquiatricas;Tipo enfermedad psiquiátrica;Psiqu. Def;Sintomas psi;Insomnio;MPSI-1;MPSI-1;A. Valpro;CBZ;GABA;ADT;iSRS;iSRS/N;AD-Atip;BZD;Antipsi-T;Antip-A;Antecedentes Caidas;Núm caídas;Antecedentes Discapacidades;Antecedentes Otros;Otro M1;Otro M2;Otro M3;Otro M4;Otro M5;Otro M6;Otro M7;Cromo;Bisacodi;Metocarbam;Antigotosos;Metotrexa;Leflunomida;Cloroqui-Hidr;Bifosfonatos;Anticonv.;Levodopa;Vit y complementos;Simeticona;Antimuscarin;Ergotamina;Acetam;IBP;Antiac.;Anti-H2;AINES;Opiodes;Sucralfato;Sulfazalacina;SulfaFer;Anti-H1;Naturista;Esteroide O;Antecedentes Cirugias;Tipo cirugía;Antecedentes Menarca;Antecedentes Menopausia;Tiempo menstruación;Tiempo menopausia;Antecedentes Embarazos;Antecedentes abortos;Antecedentes Partos;Antecedentes Cesareas;Antecedentes Hijos Vivos;Antecedentes Familiar DC;Familiar con DC;Tipo DC AF;Antecedentes Familiares Otros;Lawton Pre Salir Casa;Lawton Pre Caminar Habitacion;Lawton Pre Usar Telefono;Lawton Pre Ir Compras;Lawton Pre Tomar Medicamento;Lawton Pre Abrir Cerrar Ventanas;Lawton Pre Manejar Dinero;Lawton Pre Encen Apag Radio Tv;Lawton Pre Manipular Interruptores;Lawton Pre Hacer Propia Comida;Lawton Pre Manipular Llaves;Lawton Pre Cortarse Uñas;Lawton Pre Trabajo Liviano Casa;Lawton Pre Trabajo Pesado Casa;Lawton Act Salir Casa;Lawton Act Caminar Habitacion;Lawton Act Usar Telefono;Lawton Act Ir Compras;Lawton Act Tomar Medicamento;Lawton Act Abrir Cerrar Ventanas;Lawton Act Manejar Dinero;Lawton Act Encen Apag Radio Tv;Lawton Act Manipular Interruptores;Lawton Act Hacer Propia Comida;Lawton Act Manipular Llaves;Lawton Act Cortarse Uñas;Lawton Act Trabajo Liviano Casa;Lawton Act Trabajo Pesado Casa;Total Lawton Previo Sin Dificultad;Total Lawton Previo Con Dificultad;Total Lawton Previo Con Ayuda;Total Lawton Previo No;Total Lawton Actual Sin Dificultad;Total Lawton Actual Con Dificultad;Total Lawton Actual Con Ayuda;Total Lawton Actual No;Diferencia Lawton;Observacion Lawton;Minimental Ori Año;Minimental Ori Epoca;Minimental Ori Mes;Minimental Ori Dia;Minimental Ori Dia Semana;Minimental Ori Pais;Minimental Ori Departamento;Minimental Ori Ciudad;Minimental Ori Lugar;Minimental Ori Piso;Minimental Reg Repeticion Palabras;Minimental Ate Calculo;Minimental Recobro;Minimental Len Identificacion Objetos;Minimental Len Repeticion Frase;Minimental Len Comando;Minimental Len Lectura Frase;Minimental Len Escritura;Minimental Copiado Patron;Total Minimental;Observacion Minimental;Moca Vis Union Grafo;Moca Vis Copiar Cubo;Moca Vis Reloj Contorno;Moca Vis Reloj Numeros;Moca Vis Reloj Agujas;Moca Identificacion Imagenes;Moca Memoria Intento 1;Moca Memoria Intento 2;Moca Ate Lista Numeros1;Moca Ate Lista Numeros2;Moca Ate Serie Letras;Moca Ate Restas;Moca Len Repeticion Frases;Moca Len Fluidez;Moca Abstraccion;Moca Recuerdo Diferido;Moca Recuerdo Intrusiones;Moca Ori Dia Del Mes;Moca Ori Mes;Moca Ori Año;Moca Ori Dia De Semana;Moca Ori Lugar;Moca Ori Ciudad;Moca Menos 12 Anios Estudio;Total Moca;Observacion Moca;Total Gds;Cdr Memoria;Cdr Orientacion;Cdr Juicio;Cdr Vida Social;Cdr Hogar Y Aficiones;Cdr Cuidado Personal;Total Cdr;Observacion Cdr;Deterioro Cognitivo;Observacion Especialista;Médico Atención   2997 non-null   object\n",
      "dtypes: object(1)\n",
      "memory usage: 23.5+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "# Instanciar y usar el preprocesador\n",
    "preprocessor = DataCleaner(X, y)\n",
    "data_analyzer = DataAnalyzer()\n",
    "\n",
    "\n",
    "preprocessor.encode_features(target_column='income', method='onehot')\n",
    "\n",
    "# Limpieza de duplicados y datos nulos\n",
    "preprocessor.delete_null_data()\n",
    "#preprocessor.delete_duplicate_rows()\n",
    "#preprocessor.delete_Object_columns()\n",
    "\n",
    "# Imputación de valores faltantes\n",
    "#X_imputed = preprocessor.impute_missing_values()\n",
    "\n",
    "# Estandarización\n",
    "preprocessor.standardize()\n",
    "\n",
    "# normalización\n",
    "preprocessor.normalize_features()\n",
    "\n",
    "#detectar y eliminar outliers\n",
    "preprocessor.delete_outliers().value_counts()\n",
    "\n",
    "#balancear datos\n",
    "preprocessor.balance_data()\n",
    "\n",
    "#generar columnas polinomiales\n",
    "#xfold = preprocessor.generate_polynomial_columns()\n",
    "\n",
    "#preprocessor.reduce_dimensionality(n_components=2,replace=True)\n",
    "\n",
    "data = pd.concat([preprocessor.X, preprocessor.y], axis=1)\n",
    "print(data_analyzer.describe_data(data=data))\n",
    "data_analyzer.visualize_correlation(data=data)\n",
    "data_analyzer.visualize_data(data, kind='boxplot')\n",
    "data_analyzer.visualize_data(data, kind='histogram')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = preprocessor.X\n",
    "y = preprocessor.y\n",
    "\n",
    "\n",
    "# Inicializar el selector de características\n",
    "selector = FeatureSelector(X, y)\n",
    "\n",
    "# 1. Selección de características con Chi-squared\n",
    "chi2_result = selector.select_features_chi2(k=14)\n",
    "FeatureVisualizer.plot_scores(chi2_result['features'], chi2_result['scores'], title='Chi-squared Scores')\n",
    "\n",
    "# 2. Selección de características con Spearman\n",
    "spearman_result = selector.select_features_spearman(threshold=0.01)\n",
    "FeatureVisualizer.plot_correlations(spearman_result['selected_features'], spearman_result['correlations'], title='Spearman Correlation Coefficients')\n",
    "\n",
    "# 3. Selección de características con Lasso\n",
    "lasso_result = selector.lasso_feature_selection(alpha=0.01)\n",
    "FeatureVisualizer.plot_coefficients(lasso_result['selected_features'], lasso_result['coefficients'], title='Lasso Coefficients')\n",
    "\n",
    "# 4. Selección de características con Sequential Feature Selector\n",
    "sfs_result = selector.sequential_feature_selection(n_features_to_select=13, direction='forward')\n",
    "print(\"Sequential Feature Selection Selected Features:\", sfs_result['selected_features'])\n",
    "\n",
    "# 5. Importancia de características con Random Forest\n",
    "rf_result = selector.random_forest_feature_importance(n_features=14)\n",
    "FeatureVisualizer.plot_importances(rf_result['selected_features'], rf_result['importances'], title='Random Forest Feature Importances')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
